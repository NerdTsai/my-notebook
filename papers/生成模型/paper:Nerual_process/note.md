### Nerual Process



### 1. Introduction

#### 1.1 问题提出

##### 1) 神经网络的优缺点

- 优点 : 在测试时能够快速得到结果.
- 缺点 : 因为其在训练后无法再被更新, 因此神经网络在训练完成后引用到测试集是已经变为了一种确定性算法. 这样的方法的有点

##### 2) 高斯过程的优缺点

- 优点 : 
  - 高斯过程不是确定性算法, 根据采样可以获得无数次个预测函数. 因此可以捕捉预测过程中的不确定性.
  - 高斯过程不需要大量时间去进行training. 并且在测试阶段具有极强的灵活性.
- 缺点:
  - 计算量大, 在进行矩阵运算时需要耗费很大计算资源.
  - 对于不同的kernel函数需要定义不同的优化过程. 无法向神经网络这样简介.

#### 1.2 Nerual process

神经过程的提出就是为了改进上述两种方法. 

##### 1) 相比于NN

- 学习的是模型的分布, 而不是一个确定性模型.
- 在根据已观测数据分析新数据的时候能够处理不确定性.

##### 2) 相比于GP

- 大幅降低训练复杂度. 
- 移除了对于kernel函数的限制和依赖.



### 2. Model

#### 2.1 作为一个随机过程的神经过程

##### 1) 随机过程定义

下面摘自维基百科:

*定义 : 在概率论概念中，随机过程是随机变量的集合。若一随机系统的样本点是随机函数，则称此函数为样本函数，这一随机系统全部样本函数的集合是一个随机过程*

我的理解 :

> 1. 这里的样本函数皆为一个分布中抽样出来的, 而我们要求的就是这个可以抽样出函数的**确定性分布**.  然后从这个**确定性分布**中可以采样出**不确定性函数**
> 2. 其实本质上求这个分布的过程是一个求泛函最优解的过程. 我们求解神经网络的最优解是对一个函数进行最优化, 相对应的, 在泛函上进行最优化我们是要求出一个最优函数 $q$.

基本概念 :

在随机过程中, 每组数据都是一个变量, 有N个数据就有N个变量. 这些变量应该尽可能的满足函数 $f$, 而函数 $f$ 是从一个分布 $\mathcal{F}$ 中采样出来的. 

##### 2) 符号定义

在本文中的符号定义:

- $f$ : 某一个采样出来的函数.


- $\mathcal{F}$ : 使我们所有求的确定性分布. 

- $\mathcal{F}:\mathcal{X}\to\mathcal{Y}$ . $\mathcal{X},\mathcal{Y}$ 分别是输入数据和输出数据\. 其数据构成如下:

  ![](./pictures/1) ![](./pictures/2)

- $\rho_{x_{1:n}}$ 是所有数据的联合概率.

  ![](./pictures/3)

##### 3) 随机过程拥有的两个特性

- **可交换性**

  是指数据的无序性: 交换数据的顺序, 联合分布不变

  ![](./pictures/4)

- **连续性**

  指的是, 一部分的数据的边缘分布可用其他变量的积分来求得.

  ![](./pictures/5)

#### 2.1(1) $\mathcal{F}$ 的推导过程

本节最好结合我的另外一个笔记, [高斯过程] 来看, 这样会理解的深刻一些.

现在定义联合概率为 $p(f,y|x)$.

##### 1) 边缘概率

首先, 我们知道我们从 $\mathcal{F}$ 可以采样出很多很多的函数, 关于数据的边缘分布应该符合下面的式子:

![](./pictures/6)

其中, $f \sim F$.

在高斯过程中, F就是根据核函数和其对应的优化过程, 利用已观测数据得出一个高维高斯, 这个高维高斯的维度是已观测数据的size.

##### 2) 加入噪声

这一步相当于数据增强. 对应着高斯过程笔记的2.4节内容. 

首先看条件分布 $p(y|f,x)$

![](./pictures/7)

这样情况下的边缘分布为:

![](./pictures/8)

##### 3) 参数化泛函

我们在上面假设的是, $f$ 可以是任何函数, 但是实际上这样是无法计算的, 必须要要赋予 $f$ 一个具体的函数形式, 然后通过调整这个函数的参数来具现化函数, 这里为了提高模型capacity, 这里使用的是神经网络 $g(x,z$) , 其中, $x$ 是输入, $z$ 是参数. 

注意!!!! 现在我们面对一个新数据 $x$ 的时候, 做法从

**从一个泛函中采样出函数应用于与 $x$ **		变为了 $\large\to$

**从一个分布中采样出参数 $z$,  将其应用于神经网络 $g$ , 再将 $x$ 输入这个神经网络.**



##### 4) 再次强调现在的目标

**从一个分布中采样出参数 $z$,  将其应用于神经网络 $g$ , 再将 $x$ 输入这个神经网络.**

即, $\mathcal{F}=g(x,z)$, 其中, $z\sim q(z)$

那么现在的目标就是求 $p(z)$



#### 2.1(2) 变分法求 $q(z)$

变分推理详见 PRML 第十章. 我也放上了我的一部分笔记, [变分推理(2)] 由于太多只做了一部分, 结果还因为忘记保存丢了一大部分, 生气啊, 不过放上的那些也够用了. 

我们现在要求的 $q(z)$ 的变分后验 $q(z|x_{1:n},y_{1:n})$, 这里用到了第二个**神经网络**. 但不是完全的输入 $x,y$ 输出 $z$ 的形式, 因为不是一组 $x,y$ 对应一个 $z$ , 其只为一个变量. 

##### 1) 分解边缘分布

变分法是从分解边缘分布 $p(x)$ 开始的.  

但是在这篇文章中的边缘分布是 $p(y_{1:n}|x_{1:n})$, 由于在后续的分析中, $x_{1:n}$ 一直处于条件的位置, 因此为了简化运算, 这里将 $p(y_{1:n}|x_{1:n})$ 设为 $p(y)$ . 

之后的运算中也不会再出现 $x$ , 但是有 y 的地方, 就肯定有一个条件的 $x_{1:n}$

分解公式为:
$$
\begin{aligned}
p(y) &= p(y,z)/p(z|y) = \frac{p(y,z)}{q(z)} /\frac{p(z|y)}{q(z)} \to\\\ln p(y)&=\ln\frac{p(y,z)}{q(z)}-\ln\frac{p(z|y)}{q(z)}\\&=\int q(z)\ln\frac{p(y,z)}{q(z)}dz - \int q(z)\ln\frac{p(z|y)}{q(z)}dz \\&=ELBO\ +\ KL(q||p)
\end{aligned}
$$

##### 2) 求下界ELBO

我们是希望能够使得关于潜在变量的后验分布 $p(z|y)$ 去更新先验分布 $q(z)$, 所以要最小化 $KL$ 距离. 即, 最大化 ELBO, 由于KL距离的值一定是大于等于0的, 因此:
$$
\begin{aligned}
\ln p(y) &\geq ELBO\\&=\int q(z)\ln\frac{p(y,z)}{q(z)}dz \\&
\end{aligned}
$$
由于这个里面的 $p(y,z)$ 是无法计算的, 因此我们需要对其进行求解, 并且, 这里的 $q(z)$ 是做了零先验假设, 但是在有**上下文数据**的情况下, 我们可以使用先验, 即: $q(z)\to q(z|y)$. 下面的 $p(z)$ 是我们假设的 $z$ 的真实分布. 
$$
\begin{aligned}
\ln p(y) &\geq \int q(z)\ln\frac{p(y,z)}{q(z)}dz \\&=\int q(z|y)\ln \frac{p(y|z)p(z)}{q(z|y)}\\&=\mathbb{E}_{q(z|y)}\Big[ \ln p(y|z)-\ln \frac{p(z)}{q(z|y)} \Big]\\&=\mathbb{E}_{q(z|y)}\Big[ \sum_{i=1}^n\ln p(y_i|z)-\ln \frac{p(z)}{q(z|y)} \Big]
\end{aligned}
$$
将 $x$ 加入式子就是:

![](./pictures/9)

##### 3) 应用到实际的计算 

我们是希望能够用一些部分已知数据对 $x_{1:m},y_{1:m}$, 去求解另一部分的数据对应的 $x_{m+1,n},y_{m+1:n}$, 即:
$$
p(y_{m+1:n}|x_{1:n}, y_{1:m})
$$
这样就有如下的式子(不想推了):

![](./pictures/10)

由于真实概率 $p(z|x_{1:m},y_{1:m})$ 是无法处理的, 因此这里需要用变分后验近似分布 $q(z|x_{1:m},y_{1:m})$ 去替代它.

这里最难理解的一个地方是, 如何优化得到 $q(z|x_{1:m},y_{1:m})$.  

我的个人理解是, 这里其实就是用的简单的随即下降加上一些对从分布中生成数据进行梯度下降的方法, 这个在第2.4节会细讲.

#### 2.2 Distribution over functions 

这一节虽然短, 但是确实最精华, 最insight的地方, 推荐去看原文. 害怕自己理解不到位.

首先在讲这一节的内容之前很有必要看第2.4节的内容, 其先直接去看2.4节.

- **Test 时的灵活性**

  - 其中很重要的一点是,  **训练神经网络应该用全部数据去训练.**  是为了提供神经网络可以生成任何参数的能力.
  - 并且, 训练完成后可以只选择一部分数据去作为 **上下文数据** 去生成参数. 这就是提供了选择性以及特性性. 

  这里就可以做一件非常有意思的事情!!!!!!  比如用在对话分析的地方就可以进行语言风格分类, 然后根据提供的上下文语句实现不同风格的对话. 可以帮助你过圣诞节, 春节, 清明节, 七夕节(虽然和我没什么关系).

#### 2.3 Global latent variable

还是接着上一步**整体数据**与**上下文数据**的区别展开的讨论.

当我们不向数据新的数据提供 **上下文数据** 的时候, 像2.4.2)展示的那样, $p(z)$ 用到的只是训练 **数据的平均信息**. 

而当提供了一些上下文数据的时候, 就会为 $p(z)$ 提供先验, 使其成为 $q(z|x_{1:m},y_{1:m})$.

不同的上下文数据会提供不同的先验. 产生不同的结果.

整个过程其实相当于一个贝叶斯框架下的模型, 不停地在新的上下文中更新 $q(z)$ , 最后就拥有了对所有的上下文进行编码的能力.

#### 2.4 The Nerual process model

##### 1) 概率图

![](./pictures/11)

##### 2) 计算图

![](./pictures/14)

##### 3) 三个组成

- **Encoder $h$** : 利用一个神经网络 $h$ 去处理 **上下文数据(context data)**. 这里经过对上下文数据的处理得到的是一个这写上下文数据的特征参数. 这个参数可以在下一步作为分布函数的参数.  这里非常值得注意的一点是 **: 训练神经网络应该用全部数据去训练.** 

  通过上面的计算图可以看出来, 在一次计算中, Encoder会被用两次. 一次用于**上下文数据**, 一次用于**目标数据**.

- **Aggregator $a$** : 这个部分就是将上下文数据的信息用来形成分布  $q(z|x_{1:m},y_{1:m})$ , 进而采样 $z$. 这里用的方法是: 

  ![](./pictures/13)

  ![](./pictures/12)

  ​

  这样就有了采样出泛函参数 $z$ 的分布, 也就有了泛函的形式 $g(x, z)$. 这个和Encoder一样也要用两次.

- **Conditional decoder $g$** : 这一部分处理的是target数据, $x_T,y_T$

  用的是最直接的神经网络前向计算 : $y_T = g(z,x_T)$.



#### 4. Result

第四章感觉很重要, 但是我不想写了....