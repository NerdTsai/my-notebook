## My-notebooks

These are the notebooks about what I have read for quickly recall when I want to check sone points I have learned. 

**All IN CHINESE**

### 1. Books&courses

Notebooks about books and courses I read. 

#### 1.1 Casuality

[causality models reasoning and inference by Pearl.J ](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=2ahUKEwigvNqQy6reAhUKV7wKHXJOChEQFjABegQIBRAC&url=http%3A%2F%2Fblog.sciencenet.cn%2Fhome.php%3Fmod%3Dattachment%26filename%3DCausality_%2520models%252C%2520reasoning%252C%2520and%2520inference%255BJudea_Pearl%255D.pdf%26id%3D56698&usg=AOvVaw3uRYPOpJK0JIovNrzb24MP)

###### State : 

- [**Unfinished**] chapter 1 : Introduction to Probabilities, Graphs, and Causal Models

#### 1.2 Deep learning

[Deep Learning](www.deeplearningbook.org)

###### State : 

- [**Finished**] chapter1 : [Introduction](http://www.deeplearningbook.org/contents/intro.html)
- [**Finished**] chapter2 : [Linear Algebra](http://www.deeplearningbook.org/contents/linear_algebra.html)
- [**Finished**] chapter3 : [Probability and Information Theory](http://www.deeplearningbook.org/contents/prob.html)
- [**Finished**] chapter4 : [Numerical Computation](http://www.deeplearningbook.org/contents/numerical.html)
- [**Finished**] chapter5 : [Machine Learning Basics](http://www.deeplearningbook.org/contents/ml.html)
- [**Finished**] chapter6 : [Deep Feedforward Networks](http://www.deeplearningbook.org/contents/mlp.html)
- [**Finished**] chapter7 : [Regularization for Deep Learning](http://www.deeplearningbook.org/contents/regularization.html)
- [**Finished**] chapter8 : [Optimization for Training Deep Models](http://www.deeplearningbook.org/contents/optimization.html)

##### 1.3 PRML

[Pattern Recognition and Machine Learning](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)

###### State :

- [**Unfinished**] chapter1 : Introduction
  - Only 1.5 section
- [**Finished**] chapter2 : Probability Distributions
- [**Finished**] chapter8 : Graphical Models
- [**Unfinished**] chapter9 : Mixture Models and EM
- [**Unfinished**] chapter10 : Approximate Inference

##### 1.4 Gaussian Process

[Gaussian Processes for Machine Learning](http://www.gaussianprocess.org/gpml/chapters/RW.pdf)

###### State : 

- [**Unfinished**] chapter2 : Regression

### 2. Papers

Notebooks of some important papers I have read about NLP and ML, DL

#### 2.1 Deep learning

- [SMASH: One-Shot Model Architecture Search through HyperNetworks](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj-zsaH4KreAhWDEbwKHQxOC28QFjAAegQIBRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1708.05344&usg=AOvVaw0yUB8ceNPswuMEPH_JPwwZ)
- Explanation of deep nerual network
- [Structural Deep Embedding for Hyper-Networks](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjlx5O14KreAhWKebwKHbOXAAIQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1711.10146&usg=AOvVaw2pBPbwQGn8OvTFb3TCTHGD)
- [Class Imbalance, Redux](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiwr8XF4KreAhUO87wKHSkkBZEQFjAAegQICRAB&url=https%3A%2F%2Fwww.semanticscholar.org%2Fpaper%2FClass-Imbalance%252C-Redux-Wallace-Small%2Fa8ef5a810099178b70d1490a4e6fc4426b642cde&usg=AOvVaw0AWbBdxrrBImto84KUQUWj)
- [Sampling Matters in Deep Embedding Learning](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjVu7TV4KreAhUK6bwKHa7YDUsQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.07567&usg=AOvVaw2AzFtahdZxHVkmkaaY0M2G)
- [Training Very Deep Networks](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwig757g4KreAhVHebwKHR3CBLIQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1507.06228&usg=AOvVaw25THsCZz0tT7wfewnnpv7f)

#### 2.2 Generative model

- [Learning in Implicit Generative Models](https://arxiv.org/abs/1610.03483)
- [Neural Processes](https://arxiv.org/abs/1807.01622)

#### 2.3 Knowledge graph

- [Learning Structural Node Embeddings via Diffusion Wavelets](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjyuqi54areAhUITrwKHc6HDxsQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1710.10321&usg=AOvVaw0nyAIUNYfen6IcZ4eIf4Dt)
- [A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjUmd_N4areAhVK5rwKHfwLD2IQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1709.07604&usg=AOvVaw2jPvlSeC_JTgBd2O-J9Gk5)
- [On Inductive Abilities of Latent Factor Models for Relational Learning](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiIh8bh4areAhWFxbwKHYEBBdAQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1709.05666&usg=AOvVaw3Rthl3lVJSl0IgnZHFlohP)
- [A Review of Relational Machine Learning for Knowledge Graphs](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiesPXp4areAhWMx7wKHbzjAycQFjAAegQICRAB&url=http%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F7358050%2F&usg=AOvVaw2KgZ0OARERi3azVzTQ16yL)
- [Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach](https://www.google.com/url?sa=t&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj-qKP04areAhVGyLwKHduMCWAQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.05674&usg=AOvVaw3R7psWcU52gGbNtRoRrQnl)

#### 2.4 Representation learning

- [Hierarchical Density Order Embeddings](https://arxiv.org/abs/1804.09843)
- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)
- [Neural Word Embedding as Implicit Matrix Factorization](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)
- [Dependency-Based Word Embeddings](http://www.aclweb.org/anthology/P14-2050)
- [Deep contextualized word representations](https://arxiv.org/abs/1802.05365)
- [Improved Word Representation Learning with Sememes](http://nlp.csai.tsinghua.edu.cn/~xrb/publications/ACL-17_sememe.pdf)

#### 2.5 Application of graph neural network(GNN) in NLP

- [Graph Convolution over Pruned Dependency Trees Improves Relation Extraction](https://arxiv.org/abs/1809.10185)
- [Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling](https://arxiv.org/abs/1703.04826)
- [Learning Deep Generative Models of Graphs](https://arxiv.org/abs/1803.03324)
- [Neural Relational Inference for Interacting Systems](https://arxiv.org/abs/1802.04687)

#### 2.6 Theory about graph neural network

- [Relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261)

#### 2.7 Research on language characteristics

- [Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Path](https://arxiv.org/abs/1508.03720)

#### 2.8 Relation extraction

- [Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjPmt3426reAhWBxbwKHcrJBvYQFjAAegQICBAC&url=http%3A%2F%2Fwww.emnlp2015.org%2Fproceedings%2FEMNLP%2Fpdf%2FEMNLP203.pdf&usg=AOvVaw2X-KpBZK2HEtmE4vGifceq)
- [Neural Relation Extraction with Selective Attention over Instances](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjo6e2E3KreAhVTO7wKHYAPA6sQFjAAegQICBAC&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP16-1200&usg=AOvVaw3WPrjgBYUgx6NUC-Ss5dwp)
- [Weakly-supervised Relation Extraction by Pattern-enhanced Embedding Learning](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwi5osiJ3KreAhULXbwKHb46D80QFjABegQICBAC&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1711.03226&usg=AOvVaw1drt0h6N57ydPO6OZW9AW9)
- [CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjdrYWR3KreAhUGXbwKHVHfAJAQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1610.08763&usg=AOvVaw3YTyQnb6nCbiMrlW0F2XL6)
- [Learning with Noise: Enhance Distantly Supervised Relation Extractionwith Dynamic Transition Matrix](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi20MyZ3KreAhXMw7wKHclpAkkQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1705.03995&usg=AOvVaw3RTl5BGG8i414bWeQ0FMxA)
- [Deep Residual Learning for Weakly-Supervised Relation Extraction](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjCqtah3KreAhVFErwKHdTtAVgQFjAAegQICRAC&url=https%3A%2F%2Fwww.cs.ucsb.edu%2F~william%2Fpapers%2FResCNN.pdf&usg=AOvVaw0TD4o3TCvi3vvcUJ3RkGSs)
- [Cross-Sentence N-ary Relation Extraction with Graph LSTM](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwivjaSm3KreAhVHwrwKHdQ0BRsQFjAAegQIBRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1708.03743&usg=AOvVaw3TwfPEzMcQzmB5mXLfIO4n)
- [Distant Supervision for Relation Extraction beyond the Sentence](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjcyIyt3KreAhUK6LwKHfikC1YQFjAAegQICRAC&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FE17-1110&usg=AOvVaw2Ev7O7Ao9LvJkMcX70LC_W)

#### 2.9 Casuality inference

- [Causal Effect Inference with Deep Latent-Variable Models](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj6iJyn3areAhWHPXAKHWkWCyAQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1705.08821&usg=AOvVaw1KEFkByhpdbgrtg2CW02fs)

#### 2.10 Dialogue system

- [Conversational Contextual Cues: The Case of Personalization and History for Response Ranking](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiUiL_A3areAhWOdHAKHee-Cf0QFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.00372&usg=AOvVaw09ILZmuwk-Ikxl9ENKq4BW)
- [Neural Responding Machine for Short-Text Conversation](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi4-Lrv3areAhVLPHAKHYmAA0sQFjAAegQICRAC&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP15-1152&usg=AOvVaw1S-T39RTcIjwDQoJSAWOav)

#### 2.11 Coreference resolution

- [Multi-Task Identification of Entities, Relations, and Coreference](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjxvP6J3qreAhVIEXAKHZKfB0EQFjAAegQICBAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1808.09602&usg=AOvVaw0GJ7V9bnUTiOpLxdVIxYn_)
- [End-to-end Neural Coreference Resolution](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjc9omY3qreAhVIFYgKHZF4BgUQFjAAegQIBRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1707.07045&usg=AOvVaw22sdXxlsgvxl6ES9HkMmc0)

#### 2.12 Machine translation

- [SOCKEYE : A Toolkit for Neural Machine Translation](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjZtsPF3qreAhVGMd4KHUbeCHEQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1712.05690&usg=AOvVaw24QqWo2WsvwHZ_6u_VlOWX)
- [All You Need Is Attention](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiK16_T3qreAhWJ62EKHSy6BhEQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&usg=AOvVaw2ceXGQohV5Kx51VSkfkG08)

#### 2.13 Machine reading

- [Reinforced Mnemonic Reader for Machine Reading Comprehension](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj8pvzg3qreAhUIA4gKHZUIDV4QFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1705.02798&usg=AOvVaw0oP6-cFd57YuaEwCuCsA0X)
- [Teaching Machines to Read and Comprehend](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwisvbrn36reAhWLf7wKHaw6CSwQFjAAegQICRAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1506.03340&usg=AOvVaw0EdBVMy_x4DXAksZuj0EaB)



### 3. Topics

#### 3.1 About programing

- How to deal with big file
- Introduction about Chainer
- Introduction about Pandas
- Introduction about tensorflow
- Programing tricks in python
- Python mechanism
- Introduction about SQL

#### 3.2 About machine learning

- Bagging, boosting
- Bayes error
- Befree
- Dropout
- Hessian matrix
- Imbalance data
- LSTMs
- MLE&MAP
- Regularation
- Semantics parsing
- Text similarity
- posterior&prior
- Convolution neural network
- Variational inference
- NER
- Inductive bias
- Lapalance matrix in network thermal conduction
- Lagrangian
- Spectral clustering
- Metrics